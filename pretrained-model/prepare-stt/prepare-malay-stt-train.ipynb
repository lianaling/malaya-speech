{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://cdn.commonvoice.mozilla.org/cv-corpus-5.1-2020-06-22/id.tar.gz\n",
    "# !tar -zxf id.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://f000.backblazeb2.com/file/malay-dataset/speech/semisupervised-26-02-2021-part2.tar\n",
    "# !mkdir part1-v2\n",
    "# !tar -xf semisupervised-26-02-2021-part2.tar -C part1-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://f000.backblazeb2.com/file/malay-dataset/speech/semisupervised-26-02-2021-part3.tar\n",
    "# !mkdir part2-v2\n",
    "# !tar -xf semisupervised-26-02-2021-part3.tar -C part2-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://f000.backblazeb2.com/file/malay-dataset/speech/semisupervised-26-02-2021-part4.tar\n",
    "# !mkdir part3-v2\n",
    "# !tar -xf semisupervised-26-02-2021-part4.tar -C part3-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://f000.backblazeb2.com/file/malay-dataset/speech/semisupervised-24-03-2021-part1.tar\n",
    "# !tar -xf semisupervised-24-03-2021-part1.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://f000.backblazeb2.com/file/malay-dataset/speech/semisupervised-24-03-2021-part2.tar\n",
    "# !tar -xf semisupervised-24-03-2021-part2.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://f000.backblazeb2.com/file/malay-dataset/speech/semisupervised-24-03-2021-part3.tar\n",
    "# !tar -xf semisupervised-24-03-2021-part3.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://f000.backblazeb2.com/file/malay-dataset/speech-bahasa.zip\n",
    "# !unzip speech-bahasa.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://f000.backblazeb2.com/file/malay-dataset/streaming.zip -O wikipedia-asr.zip\n",
    "# !unzip wikipedia-asr.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wget https://f000.backblazeb2.com/file/malaya-speech-model/data/news-speech.zip\n",
    "# wget https://f000.backblazeb2.com/file/malaya-speech-model/collections/transcript-news.json\n",
    "# unzip news-speech.zip -d news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://f000.backblazeb2.com/file/malaya-speech-model/data/trainset-audiobook.tar.gz\n",
    "# !wget https://f000.backblazeb2.com/file/malaya-speech-model/data/text-audiobook.tar.gz\n",
    "# !tar -xf trainset-audiobook.tar.gz\n",
    "# !tar -zxf text-audiobook.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\liana\\Documents\\Projects\\malaya-speech\\pretrained-model\\prepare-stt\\prepare-malay-stt-train.ipynb Cell 1'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/liana/Documents/Projects/malaya-speech/pretrained-model/prepare-stt/prepare-malay-stt-train.ipynb#ch0000000?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/liana/Documents/Projects/malaya-speech/pretrained-model/prepare-stt/prepare-malay-stt-train.ipynb#ch0000000?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mglob\u001b[39;00m \u001b[39mimport\u001b[39;00m glob\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/liana/Documents/Projects/malaya-speech/pretrained-model/prepare-stt/prepare-malay-stt-train.ipynb#ch0000000?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtqdm\u001b[39;00m \u001b[39mimport\u001b[39;00m tqdm\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_directory = '/home/husein/speech-bahasa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7490, 10)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(f'{base_directory}/cv-corpus-5.1-2020-06-22/id/validated.tsv', sep = '\\t')\n",
    "df = df[(df['sentence'].str.len() > 5) & (df['sentence'].str.count(' ') > 0)]\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7490"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_commonvoice = []\n",
    "for i in range(len(df)):\n",
    "    p = f\"{base_directory}/cv-corpus-5.1-2020-06-22/id/clips/{df['path'].iloc[i]}\"\n",
    "    t = df['sentence'].iloc[i]\n",
    "    if len(t) < 5:\n",
    "        continue\n",
    "    id_commonvoice.append((p, t))\n",
    "\n",
    "len(id_commonvoice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1008453"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "malay = glob(f'{base_directory}/part*/output-wav/*.wav')\n",
    "len(malay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1322836"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "malay.extend(glob(f'{base_directory}/part*/semisupervised/output-wav/*.wav'))\n",
    "len(malay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(565, 200, 698)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "khalil = glob(f'{base_directory}/tolong-sebut/*.wav')\n",
    "mas = glob(f'{base_directory}/sebut-perkataan-woman/*.wav')\n",
    "husein = glob(f'{base_directory}/sebut-perkataan-man/*.wav')\n",
    "len(khalil), len(mas), len(husein)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 537/537 [00:00<00:00, 5034.84it/s]\n"
     ]
    }
   ],
   "source": [
    "khalils = []\n",
    "for i in tqdm(khalil[:-int(len(khalil) * 0.05)]):\n",
    "    try:\n",
    "        t = i.split('/')[-1].replace('.wav','')\n",
    "        text = f'tolong sebut {t}'\n",
    "        khalils.append((i, text))\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 190/190 [00:00<00:00, 193426.64it/s]\n"
     ]
    }
   ],
   "source": [
    "mass = []\n",
    "for i in tqdm(mas[:-int(len(mas) * 0.05)]):\n",
    "    try:\n",
    "        t = i.split('/')[-1].replace('.wav','')\n",
    "        text = f'sebut perkataan {t}'\n",
    "        mass.append((i, text))\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 664/664 [00:00<00:00, 223480.81it/s]\n"
     ]
    }
   ],
   "source": [
    "huseins = []\n",
    "for i in tqdm(husein[:-int(len(husein) * 0.05)]):\n",
    "    try:\n",
    "        t = i.split('/')[-1].replace('.wav','')\n",
    "        text = f'sebut perkataan {t}'\n",
    "        huseins.append((i, text))\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1322836/1322836 [01:04<00:00, 20405.69it/s]\n"
     ]
    }
   ],
   "source": [
    "malays = []\n",
    "for i in tqdm(malay):\n",
    "    try:\n",
    "        p = i.replace('output-wav','output-text')\n",
    "        with open(f'{p}.txt') as fopen:\n",
    "            text = fopen.read()\n",
    "        if len(text) < 3:\n",
    "            continue\n",
    "        malays.append((i, text))\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2743/2743 [00:00<00:00, 13014.35it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2743"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikipedia = []\n",
    "wavs = glob(f'{base_directory}/streaming/*wav')\n",
    "for i in tqdm(wavs[:-int(len(wavs) * 0.05)]):\n",
    "    text = os.path.split(i)[1].replace('.wav', '')\n",
    "    wikipedia.append((i, text))\n",
    "    \n",
    "len(wikipedia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2044/2044 [00:00<00:00, 311751.18it/s]\n"
     ]
    }
   ],
   "source": [
    "news = []\n",
    "wavs = glob(f'{base_directory}/news/audio/*wav')\n",
    "\n",
    "with open(f'{base_directory}/transcript-news.json') as fopen:\n",
    "    transcript_news = json.load(fopen)\n",
    "    \n",
    "for i in tqdm(wavs[:-int(len(wavs) * 0.05)]):\n",
    "    index = i.split('/')[-1].replace('.wav','')\n",
    "    text = transcript_news[int(index)]\n",
    "    news.append((i, text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64341/64341 [00:03<00:00, 19354.11it/s]\n"
     ]
    }
   ],
   "source": [
    "audiobook = []\n",
    "wavs = glob(f'{base_directory}/combined/*wav')\n",
    "for i in tqdm(wavs):\n",
    "    t = '/'.join(i.split('<>')[1:])\n",
    "    t = t.split('.wav')[0]\n",
    "    t = t.replace('output-wav', 'output-text')\n",
    "    with open(f'{base_directory}/text-audiobook/{t}.wav.txt') as fopen:\n",
    "        text = fopen.read()\n",
    "    audiobook.append((i, text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4080/4080 [00:00<00:00, 202914.10it/s]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(f'{base_directory}/haqkiem/metadata.csv', header = None, sep = '|')\n",
    "txts = df.values.tolist()\n",
    "haqkiem = []\n",
    "for f in tqdm(txts[:-int(len(txts) * 0.05)]):\n",
    "    text = f[1]\n",
    "    text = text.split('.,,')[0]\n",
    "    f = f[0]\n",
    "    r = f'{base_directory}/haqkiem/{f}.wav'\n",
    "    haqkiem.append((r, text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import IPython.display as ipd\n",
    "\n",
    "# ipd.Audio(audiobook[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "audios = id_commonvoice + malays + wikipedia + news + audiobook + haqkiem + khalils + mass + huseins\n",
    "audios, texts = zip(*audios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1404435"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "import itertools\n",
    "\n",
    "vocabs = [\" \", \"a\", \"e\", \"n\", \"i\", \"t\", \"o\", \"u\", \"s\", \"k\", \"r\", \"l\", \"h\", \"d\", \"m\", \"g\", \"y\", \"b\", \"p\", \"w\", \"c\", \"f\", \"j\", \"v\", \"z\", \"0\", \"1\", \"x\", \"2\", \"q\", \"5\", \"3\", \"4\", \"6\", \"9\", \"8\", \"7\"]\n",
    "\n",
    "def preprocessing_text(string):\n",
    "        \n",
    "    string = unicodedata.normalize('NFC', string.lower())\n",
    "    string = ''.join([c if c in vocabs else ' ' for c in string])\n",
    "    string = re.sub(r'[ ]+', ' ', string).strip()\n",
    "    string = (\n",
    "        ''.join(''.join(s)[:2] for _, s in itertools.groupby(string))\n",
    "    )\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1404435/1404435 [01:58<00:00, 11883.65it/s]\n"
     ]
    }
   ],
   "source": [
    "processed_text = [preprocessing_text(t) for t in tqdm(texts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('/home/husein/speech-bahasa/sebut-perkataan-man/alku.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/abdiad.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/amendmen.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/agakkan.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/alatan.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/acaranya.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/mengakuri.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/amorfus.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/keaktifan.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/abah.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/ambar.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/mengamankan.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/afasia.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/amberol.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/alkasyaf.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/abuan.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/agas.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/adangkan.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/ambah.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/aksam.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/altruisme.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/agun.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/altimeter.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/pelajar.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/mengair.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/aboi.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/amanatkan.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/mengakali.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/adatkan.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/abaka.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/adunan.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/mengada.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/alem.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/administrator.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/alit.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/amanah.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/amat.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/almas.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/alhamdulillah.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/aglosia.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/akordion.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/Allahyarham.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/abun.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/ampaian.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/aju.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/agregat.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/A.M.N..wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/alibaba.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/abilah.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/amboi.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/ambek.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/akan.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/Al-Fatihah.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/alak.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/acak.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/ajukan.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/ain.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/akreditasi.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/abiogenesis.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/alamang.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/mengagakan.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/almalun.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/administrasi.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/ambi.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/AlQuran.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/alum.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/keagungan.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/agung.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/alkoholuria.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/adiningrat.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/akit.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/aktor.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/ajaran.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/Afrika.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/ali.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/akal.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/keabadian.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/alang.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/adrenosklerosis.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/amanahkan.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/along.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/aerosol.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/aksara.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/keadaan.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/abai.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/absen.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/aerotaksis.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/ambau.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/alga.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/allamah.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/am.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/berada.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/almanak.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/mengaci.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/adunkan.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/abnormal.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/adaptasi.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/akibatkan.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/abaimana.wav',\n",
       "  '/home/husein/speech-bahasa/sebut-perkataan-man/aiskrim.wav'),\n",
       " ['sebut perkataan alku',\n",
       "  'sebut perkataan abdiad',\n",
       "  'sebut perkataan amendmen',\n",
       "  'sebut perkataan agakkan',\n",
       "  'sebut perkataan alatan',\n",
       "  'sebut perkataan acaranya',\n",
       "  'sebut perkataan mengakuri',\n",
       "  'sebut perkataan amorfus',\n",
       "  'sebut perkataan keaktifan',\n",
       "  'sebut perkataan abah',\n",
       "  'sebut perkataan ambar',\n",
       "  'sebut perkataan mengamankan',\n",
       "  'sebut perkataan afasia',\n",
       "  'sebut perkataan amberol',\n",
       "  'sebut perkataan alkasyaf',\n",
       "  'sebut perkataan abuan',\n",
       "  'sebut perkataan agas',\n",
       "  'sebut perkataan adangkan',\n",
       "  'sebut perkataan ambah',\n",
       "  'sebut perkataan aksam',\n",
       "  'sebut perkataan altruisme',\n",
       "  'sebut perkataan agun',\n",
       "  'sebut perkataan altimeter',\n",
       "  'sebut perkataan pelajar',\n",
       "  'sebut perkataan mengair',\n",
       "  'sebut perkataan aboi',\n",
       "  'sebut perkataan amanatkan',\n",
       "  'sebut perkataan mengakali',\n",
       "  'sebut perkataan adatkan',\n",
       "  'sebut perkataan abaka',\n",
       "  'sebut perkataan adunan',\n",
       "  'sebut perkataan mengada',\n",
       "  'sebut perkataan alem',\n",
       "  'sebut perkataan administrator',\n",
       "  'sebut perkataan alit',\n",
       "  'sebut perkataan amanah',\n",
       "  'sebut perkataan amat',\n",
       "  'sebut perkataan almas',\n",
       "  'sebut perkataan alhamdulillah',\n",
       "  'sebut perkataan aglosia',\n",
       "  'sebut perkataan akordion',\n",
       "  'sebut perkataan allahyarham',\n",
       "  'sebut perkataan abun',\n",
       "  'sebut perkataan ampaian',\n",
       "  'sebut perkataan aju',\n",
       "  'sebut perkataan agregat',\n",
       "  'sebut perkataan a m n',\n",
       "  'sebut perkataan alibaba',\n",
       "  'sebut perkataan abilah',\n",
       "  'sebut perkataan amboi',\n",
       "  'sebut perkataan ambek',\n",
       "  'sebut perkataan akan',\n",
       "  'sebut perkataan al fatihah',\n",
       "  'sebut perkataan alak',\n",
       "  'sebut perkataan acak',\n",
       "  'sebut perkataan ajukan',\n",
       "  'sebut perkataan ain',\n",
       "  'sebut perkataan akreditasi',\n",
       "  'sebut perkataan abiogenesis',\n",
       "  'sebut perkataan alamang',\n",
       "  'sebut perkataan mengagakan',\n",
       "  'sebut perkataan almalun',\n",
       "  'sebut perkataan administrasi',\n",
       "  'sebut perkataan ambi',\n",
       "  'sebut perkataan alquran',\n",
       "  'sebut perkataan alum',\n",
       "  'sebut perkataan keagungan',\n",
       "  'sebut perkataan agung',\n",
       "  'sebut perkataan alkoholuria',\n",
       "  'sebut perkataan adiningrat',\n",
       "  'sebut perkataan akit',\n",
       "  'sebut perkataan aktor',\n",
       "  'sebut perkataan ajaran',\n",
       "  'sebut perkataan afrika',\n",
       "  'sebut perkataan ali',\n",
       "  'sebut perkataan akal',\n",
       "  'sebut perkataan keabadian',\n",
       "  'sebut perkataan alang',\n",
       "  'sebut perkataan adrenosklerosis',\n",
       "  'sebut perkataan amanahkan',\n",
       "  'sebut perkataan along',\n",
       "  'sebut perkataan aerosol',\n",
       "  'sebut perkataan aksara',\n",
       "  'sebut perkataan keadaan',\n",
       "  'sebut perkataan abai',\n",
       "  'sebut perkataan absen',\n",
       "  'sebut perkataan aerotaksis',\n",
       "  'sebut perkataan ambau',\n",
       "  'sebut perkataan alga',\n",
       "  'sebut perkataan allamah',\n",
       "  'sebut perkataan am',\n",
       "  'sebut perkataan berada',\n",
       "  'sebut perkataan almanak',\n",
       "  'sebut perkataan mengaci',\n",
       "  'sebut perkataan adunkan',\n",
       "  'sebut perkataan abnormal',\n",
       "  'sebut perkataan adaptasi',\n",
       "  'sebut perkataan akibatkan',\n",
       "  'sebut perkataan abaimana',\n",
       "  'sebut perkataan aiskrim'])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audios[-100:], processed_text[-100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bahasa-asr-train.json', 'w') as fopen:\n",
    "    json.dump({'X': audios, 'Y':processed_text}, fopen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import malaya_speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = malaya_speech.subword.generate_tokenizer(processed_text, max_subword_length = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# malaya_speech.subword.save(tokenizer, 'transducer.subword')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = malaya_speech.subword.load('transducer.subword')\n",
    "# malaya_speech.subword.encode(tokenizer, 'i hate', add_blank = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# malaya_speech.subword.decode(tokenizer, [0, 2, 133, 875])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pydub import AudioSegment\n",
    "# import numpy as np\n",
    "\n",
    "# sr = 16000\n",
    "\n",
    "# def mp3_to_wav(file, sr = sr):\n",
    "#     audio = AudioSegment.from_file(file)\n",
    "#     audio = audio.set_frame_rate(sr).set_channels(1)\n",
    "#     sample = np.array(audio.get_array_of_samples())\n",
    "#     return malaya_speech.astype.int_to_float(sample), sr\n",
    "\n",
    "# def generator(maxlen = 18, min_length_text = 2):\n",
    "#     for i in tqdm(range(len(audios))):\n",
    "#         try:\n",
    "#             if audios[i].endswith('.mp3'):\n",
    "#                 wav_data, _ = mp3_to_wav(audios[i])\n",
    "#             else:\n",
    "#                 wav_data, _ = malaya_speech.load(audios[i])\n",
    "                \n",
    "#             if (len(wav_data) / sr) > maxlen:\n",
    "#                 # print(f'skipped audio too long {audios[i]}')\n",
    "#                 continue\n",
    "                \n",
    "#             if len(processed_text[i]) < min_length_text:\n",
    "#                 print(f'skipped text too short {audios[i]}')\n",
    "#                 continue    \n",
    "\n",
    "#             yield {\n",
    "#                 'waveforms': wav_data.tolist(),\n",
    "#                 'waveform_lens': [len(wav_data)],\n",
    "#                 'targets': malaya_speech.subword.encode(tokenizer, processed_text[i], add_blank = False),\n",
    "#             }\n",
    "#         except Exception as e:\n",
    "#             print(e)\n",
    "            \n",
    "# generator = generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import tensorflow as tf\n",
    "\n",
    "# os.system('rm bahasa-asr/data/*')\n",
    "# DATA_DIR = os.path.expanduser('bahasa-asr/data')\n",
    "# tf.gfile.MakeDirs(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shards = [{'split': 'train', 'shards': 1000}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import malaya_speech.train as train\n",
    "\n",
    "# train.prepare_dataset(generator, DATA_DIR, shards, prefix = 'bahasa-asr')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "f26d1033611ca3047e42f0e5898d30dae67588d2874ee6bcffd67244cd1ed880"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
